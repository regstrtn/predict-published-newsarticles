{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import codecs\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy\n",
    "\n",
    "from datetime import timedelta, date, datetime\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model_path = \"../TrainedClassifiers\"\n",
    "test_path = \"/Test/Guardiantestvectors.txt\"\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "\n",
    "'''\n",
    "names = [\"NN\", \"SVM\", \"RBFSVM\", \"DT\",\n",
    "     \"RF\", \"AdaBoost\", \"NB\", \"LinearDiscriminantAnalysis\",\n",
    "     \"QuadraticDiscriminantAnalysis\"]\n",
    "'''\n",
    "\n",
    "names = [\"SVM\"]\n",
    "\n",
    "'''\n",
    "\n",
    "def lik(parameters):\n",
    "    m = parameters[0]\n",
    "    sigma = parameters[1]\n",
    "    k = None\n",
    "    for i in np.arange(0, len(revmle)):\n",
    "        y_exp = m*revmle + (1-m)*recmle\n",
    "        L = (len(revmle)/2 * np.log(2 * np.pi) + len(revmle)/2 * np.log(sigma ** 2) + 1 /(2 * sigma ** 2) * sum((ymle - y_exp) ** 2))\n",
    "        k = L \n",
    "    return k\n",
    "\n",
    "'''\t\n",
    "\n",
    "def regressLL(params):\n",
    "    # Resave the initial parameter guesses\n",
    "    b0 = params[0]\n",
    "    sd = params[1]\n",
    "    \n",
    "    # Calculate the predicted values from the initial parameter guesses\n",
    "    #yPred = revmle*b0 + recmle*(1-b0)\n",
    "    yPred = [x*b0+y*(1-b0) for x,y in zip(revmle, recmle)]\n",
    "\n",
    "    # Calculate the negative log-likelihood as the negative sum of the log of a normal\n",
    "    # PDF where the observed values are normally distributed around the mean (yPred)\n",
    "    # with a standard deviation of sd\n",
    "    logLik = -np.sum( stats.norm.logpdf(ymle, loc=yPred, scale=sd) )\n",
    "\n",
    "    # Tell the function to return the NLL (this is what will be minimized)\n",
    "    return(logLik)\n",
    "\n",
    "\n",
    "def evaluate(y_true,y_pred):\n",
    "    return [accuracy_score(y_true, y_pred),\n",
    "    f1_score(y_true, y_pred, average=None),\n",
    "    #f1_score(y_true, y_pred, average='micro'),\n",
    "    #f1_score(y_true, y_pred, average='macro'),\n",
    "    #f1_score(y_true, y_pred, average='weighted'),\n",
    "    #log_loss(y_true,y_pred),\n",
    "    precision_score(y_true, y_pred, average=None),\n",
    "    recall_score(y_true, y_pred, average=None)]\n",
    "\n",
    "    #roc_auc_score(y_true, y_pred)]\n",
    "\n",
    "def AnswerWithDiversity(k1,tagList,posClassLen):\n",
    "\n",
    "    print(posClassLen)\n",
    "\n",
    "    NonMainSetArray = []\n",
    "    MainSetArray = []\n",
    "\n",
    "\n",
    "    kret = np.zeros(len(k1))\n",
    "    #print(len(tagList))\n",
    "    #print(len(k1))\n",
    "\n",
    "    k2 = []\n",
    "    for i in k1:\n",
    "        k2.append(i[1])\n",
    "    countSmall = 0\n",
    "    k2 = np.array(k2)\n",
    "    k3 = k2\n",
    "    adder = 10\n",
    "    print(adder)\n",
    "    #posClassLen = posClassLen+adder\n",
    "    posClassLen = 60\n",
    "\n",
    "    ind =  k3.argsort()[-posClassLen:][::-1]\n",
    "    #print ind\n",
    "    onlyRec = np.zeros(len(k2))\n",
    "    for i in ind:\n",
    "        onlyRec[i] = 1\n",
    "    for k2iter in range(len(k2)):\n",
    "        if k2iter not in ind:\n",
    "            word = tagList[k2iter].split('&')\n",
    "            thistoadd = {\"word\":word, \"score\":k2[k2iter], \"index\":k2iter}\t\n",
    "            NonMainSetArray.append(thistoadd)\n",
    "\n",
    "    LossWordSet = []\n",
    "\n",
    "    lossCal = 0\n",
    "    #print NonMainSetArray\n",
    "\n",
    "    for indIter in ind:\n",
    "        word = tagList[indIter].split('&')\n",
    "        score = 0\n",
    "        numberAddedat = []\n",
    "        for wordIter in word:\n",
    "            flag = 0\n",
    "            for LossWordSetIter in LossWordSet:\n",
    "                if wordIter == LossWordSetIter[\"word\"]:\n",
    "                    flag = 1\n",
    "\n",
    "                    LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"]+1\n",
    "                    score = score+(k2[indIter]/LossWordSetIter[\"number\"])\n",
    "                    numberAddedat.append(LossWordSetIter)\n",
    "\n",
    "                    break\n",
    "\n",
    "            if flag == 0:\n",
    "                thistoadd = {\"word\":wordIter, \"number\":1}\n",
    "                LossWordSet.append(thistoadd)\n",
    "                numberAddedat.append(thistoadd)\n",
    "                score = score+k2[indIter]\n",
    "\n",
    "\n",
    "        #print (\"LossWordSet\")\n",
    "        #print LossWordSet\n",
    "        #for i in MainSetArray:\n",
    "            #print (\"MainSetArray\")\n",
    "        #\tprint i\n",
    "        #\tbreak\n",
    "\n",
    "        lossCal = lossCal + score\n",
    "        #print (\"numberAddedat\")\n",
    "        #print numberAddedat\n",
    "        TobeaddedinLoop = numberAddedat\n",
    "        thistoadd = {\"word\":TobeaddedinLoop, \"score\":k2[indIter], \"index\":indIter}\n",
    "        MainSetArray.append(thistoadd)\n",
    "\n",
    "    #print lossCal\n",
    "    #print(len(MainSetArray))\n",
    "    for kappa in range(500):\n",
    "        flagMain = 0\n",
    "        #print kappa\n",
    "        for i in reversed(MainSetArray):\n",
    "\n",
    "            score = 0\n",
    "            for wordIter in i[\"word\"]:\n",
    "                for LossWordSetIter in LossWordSet:\n",
    "                    if wordIter[\"word\"] == LossWordSetIter[\"word\"]:\n",
    "                        score = score+ (i[\"score\"]/LossWordSetIter[\"number\"])\n",
    "                        LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] - 1\n",
    "\n",
    "            for j in NonMainSetArray:\n",
    "                numberAddedat = []\n",
    "                score2 = 0\n",
    "                for wordIter in j[\"word\"]:\n",
    "                    for LossWordSetIter in LossWordSet:\n",
    "\n",
    "                        if wordIter == LossWordSetIter[\"word\"]:\n",
    "                            LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] + 1\n",
    "                            score2 = score2+ (j[\"score\"]/LossWordSetIter[\"number\"])\n",
    "                            numberAddedat.append(LossWordSetIter)\n",
    "\n",
    "                if score2 - score > 0:\n",
    "                    wordset = []\n",
    "                    for wordIter in i[\"word\"]:\n",
    "                        wordset.append(wordIter[\"word\"])\n",
    "                    thistoadd = {\"word\":wordset, \"score\":i[\"score\"], \"index\":i[\"index\"]}\t\n",
    "                    NonMainSetArray.append(thistoadd)\n",
    "\n",
    "                    thistoadd = {\"word\":numberAddedat, \"score\":j[\"score\"], \"index\":j[\"index\"]}\t\n",
    "\n",
    "                    MainSetArray.append(thistoadd)\n",
    "                    NonMainSetArray.remove(j)\n",
    "                    MainSetArray.remove(i)\n",
    "                    flagMain = 1\n",
    "                    break\n",
    "\n",
    "                for wordIter in j[\"word\"]:\n",
    "                    for LossWordSetIter in LossWordSet:\n",
    "                        if wordIter == LossWordSetIter[\"word\"]:\n",
    "                            LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] - 1\n",
    "\n",
    "\n",
    "            if flagMain == 1:\n",
    "                break\n",
    "\n",
    "            for wordIter in i[\"word\"]:\n",
    "                for LossWordSetIter in LossWordSet:\n",
    "                    if wordIter[\"word\"] == LossWordSetIter[\"word\"]:\n",
    "                        LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] + 1\n",
    "\n",
    "\n",
    "\n",
    "        if flagMain == 0:\n",
    "            break\n",
    "    for i in MainSetArray:\n",
    "        kret[i[\"index\"]] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #print MainSetArray\n",
    "    #print LossWordSet\n",
    "\n",
    "    return kret,onlyRec\n",
    "\n",
    "\n",
    "\n",
    "revmle = []\n",
    "recmle = []\n",
    "ymle = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Testmain(positive_class,negative_class,d1,positive_tagList,negative_tagList,todayDate):\n",
    "    print(d1)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    a = []\n",
    "    tagList = []\n",
    "    #print (len(positive_tagList))\n",
    "    #print (len(negative_tagList))\n",
    "    #print (len(negative_class))\n",
    "    timestampList = []\n",
    "\n",
    "    timenow = todayDate\n",
    "\n",
    "    posClassLen = len(positive_class)\n",
    "    for i,i1 in zip(negative_class,negative_tagList):\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"]), int(i[\"numberOfWords\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        X_test.append(a)\n",
    "        y_test.append(0)\n",
    "        tagList.append(i1)\n",
    "        timestampList.append(float(i[\"timestamp\"]))\n",
    "\n",
    "    for i,i1 in zip(positive_class,positive_tagList):\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"]), int(i[\"numberOfWords\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])] \n",
    "        a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        X_test.append(a)\n",
    "        y_test.append(1)\n",
    "        tagList.append(i1)\n",
    "        timestampList.append(float(i[\"timestamp\"]))\n",
    "\n",
    "    #print X_test[0]\n",
    "\n",
    "    X_test = numpy.array(X_test)\n",
    "    y_test = numpy.array(y_test)\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #X_test = min_max_scaler.fit_transform(X_test)\t\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    X_test = preprocessing.normalize(X_test, norm='l2')\n",
    "    #print X_test[0]\n",
    "    model = None\n",
    "\n",
    "    timestampList = numpy.array(timestampList)\n",
    "\n",
    "\n",
    "    for ia in range(len(timestampList)):\n",
    "        if timenow - timestampList[ia] != 0:\n",
    "            timestampList[ia] = 1/(timenow - timestampList[ia])\n",
    "        else:\n",
    "            print(\"timenow-timstamp = 0\")\n",
    "        if timestampList[ia] <= 0:\n",
    "            print(\"recency is zero\")\n",
    "\n",
    "    tmax = numpy.amax(timestampList)\n",
    "    for ia in range(len(timestampList)):\n",
    "        timestampList[ia] = timestampList[ia]/tmax\n",
    "\n",
    "    for name in names:\n",
    "        with open(model_path+\"/\"+name +\"Newcount\"+str(d1)+'.pkl', 'rb') as f1:\n",
    "            model = pickle.load(f1)\n",
    "\n",
    "        k1 = model.predict_proba(X_test)\n",
    "\n",
    "        print(k1.shape)\n",
    "        revmleBefore = []\n",
    "        for ia in range(len(k1)):\n",
    "            revmleBefore.append(k1[ia][1])\n",
    "\n",
    "        revmle = numpy.array(revmleBefore)\n",
    "        recmle = timestampList\n",
    "        ymle = y_test\n",
    "\n",
    "        print(revmle.shape)\n",
    "        print(recmle.shape)\n",
    "        print(ymle.shape)\n",
    "        # Make a list of initial parameter guesses (b0, b1, sd)    \n",
    "        initParams = [0.7, 1]\n",
    "\n",
    "        # Run the minimizer\n",
    "        results = minimize(regressLL, initParams, method='nelder-mead')\n",
    "        print(\"Minimiser results: \",results, results.x)\n",
    "        alpha = results['x'][0]\n",
    "        print(alpha)\n",
    "\n",
    "        for ia in range(len(k1)):\n",
    "            k1[ia][1] = alpha*k1[ia][1]+(1-alpha)*timestampList[ia]\n",
    "\n",
    "\n",
    "        k,knew = AnswerWithDiversity(k1,tagList,posClassLen)\n",
    "        scores = evaluate(y_test,k)\n",
    "        scores1 = evaluate(y_test,knew)\n",
    "        print(\"WithDiversity\")\n",
    "        print(name+\"\\t\"+str(scores))\n",
    "        print(\"WithonlyRec\")\n",
    "        print(name+\"\\t\"+str(scores1))\n",
    "        k = model.predict(X_test)\n",
    "        countSmall = 0\n",
    "        for ka in k:\n",
    "            if ka == 1:\n",
    "                countSmall = countSmall + 1\n",
    "        scores = evaluate(y_test,k)\n",
    "        #print countSmall\n",
    "        print(\"WithoutDiversity\")\n",
    "        print(name+\"\\t\"+str(scores))\n",
    "\n",
    "    #numpy.save('urlThis'+str(month)+'.npy',urlThis)\n",
    "    #print(len(urlThis))\n",
    "\n",
    "\n",
    "def main():\n",
    "    allFeatureVal = numpy.load('../FeatureInValueForm/FeatureInValueFormwithPublishDateOrdered.npy')\n",
    "    print(len(allFeatureVal))\n",
    "    relatedarticletonum = numpy.load('../FeatureInTextFormSorted/FeatureInTextFormSortedOrdered.npy')\t\n",
    "    print(len(relatedarticletonum))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(allFeatureVal)):\n",
    "        if allFeatureVal[i][\"url\"] == relatedarticletonum[i][\"url\"]:\n",
    "            count = count +1\n",
    "        #else :\n",
    "            #print(\"I m here prob\")\n",
    "    print(\"count\")\n",
    "    print(count)\t\n",
    "\n",
    "\n",
    "    #for i in range(len(relatedarticletonum))\n",
    "\n",
    "    positive_class_test = []\n",
    "    negative_class_test = []\n",
    "    count = 0\n",
    "    posart = 0\n",
    "    negart = 0\n",
    "    positive_tagList = []\n",
    "    negative_tagList = []\n",
    "    prev = 0\n",
    "    for data,tagList in zip(allFeatureVal,relatedarticletonum):\n",
    "        a = data[\"dateList\"].decode('UTF-8')\n",
    "        d1 = datetime.strptime(a, \"%Y-%m-%d\")\n",
    "        if d1.year > 2015:\n",
    "\n",
    "            if d1 != prev and count!=0 :\n",
    "\n",
    "                todayDate = time.mktime(datetime.strptime(a, \"%Y-%m-%d\").timetuple())\n",
    "\n",
    "                Testmain(positive_class_test,negative_class_test,count,positive_tagList,negative_tagList,todayDate)\n",
    "\n",
    "                posart = posart + len(positive_class_test)\n",
    "                negart = negart  + len(negative_class_test)\n",
    "\n",
    "                positive_class_test = []\n",
    "                negative_class_test = []\n",
    "                positive_tagList = []\n",
    "                negative_tagList = []\t\t\t\n",
    "\n",
    "            if int(data[\"output\"]) == 1:\n",
    "                positive_class_test.append(data)\n",
    "                positive_tagList.append(tagList[\"tagList\"].decode('UTF-8'))\n",
    "            else:\n",
    "                negative_class_test.append(data)\n",
    "                negative_tagList.append(tagList[\"tagList\"].decode('UTF-8'))\n",
    "\n",
    "            if count%1000 == 1:\n",
    "                print(count)\n",
    "            count = count+1\t\n",
    "            prev = d1\n",
    "\n",
    "        if count > 40000:\n",
    "            break\n",
    "\n",
    "    posart = posart + len(positive_class_test)\n",
    "    negart = negart  + len(negative_class_test)\n",
    "    #Testmain(positive_class_test,negative_class_test,len(allFeatureVal))\n",
    "    print(posart)\n",
    "    print(negart)\n",
    "    print(posart+negart)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
