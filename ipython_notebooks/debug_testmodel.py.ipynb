{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import codecs\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy\n",
    "\n",
    "from datetime import timedelta, date, datetime\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model_path = \"../TrainedClassifiers\"\n",
    "test_path = \"/Test/Guardiantestvectors.txt\"\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "\n",
    "'''\n",
    "names = [\"NN\", \"SVM\", \"RBFSVM\", \"DT\",\n",
    "     \"RF\", \"AdaBoost\", \"NB\", \"LinearDiscriminantAnalysis\",\n",
    "     \"QuadraticDiscriminantAnalysis\"]\n",
    "'''\n",
    "\n",
    "names = [\"SVM\"]\n",
    "\n",
    "'''\n",
    "\n",
    "def lik(parameters):\n",
    "    m = parameters[0]\n",
    "    sigma = parameters[1]\n",
    "    k = None\n",
    "    for i in np.arange(0, len(revmle)):\n",
    "        y_exp = m*revmle + (1-m)*recmle\n",
    "        L = (len(revmle)/2 * np.log(2 * np.pi) + len(revmle)/2 * np.log(sigma ** 2) + 1 /(2 * sigma ** 2) * sum((ymle - y_exp) ** 2))\n",
    "        k = L \n",
    "    return k\n",
    "\n",
    "'''\t\n",
    "\n",
    "def regressLL(params):\n",
    "    # Resave the initial parameter guesses\n",
    "    b0 = params[0]\n",
    "    sd = params[1]\n",
    "    \n",
    "    # Calculate the predicted values from the initial parameter guesses\n",
    "    #yPred = revmle*b0 + recmle*(1-b0)\n",
    "    yPred = [x*b0+y*(1-b0) for x,y in zip(revmle, recmle)]\n",
    "\n",
    "    # Calculate the negative log-likelihood as the negative sum of the log of a normal\n",
    "    # PDF where the observed values are normally distributed around the mean (yPred)\n",
    "    # with a standard deviation of sd\n",
    "    logLik = -np.sum( stats.norm.logpdf(ymle, loc=yPred, scale=sd) )\n",
    "\n",
    "    # Tell the function to return the NLL (this is what will be minimized)\n",
    "    return(logLik)\n",
    "\n",
    "\n",
    "def evaluate(y_true,y_pred):\n",
    "    return [accuracy_score(y_true, y_pred),\n",
    "    f1_score(y_true, y_pred, average=None),\n",
    "    #f1_score(y_true, y_pred, average='micro'),\n",
    "    #f1_score(y_true, y_pred, average='macro'),\n",
    "    #f1_score(y_true, y_pred, average='weighted'),\n",
    "    #log_loss(y_true,y_pred),\n",
    "    precision_score(y_true, y_pred, average=None),\n",
    "    recall_score(y_true, y_pred, average=None)]\n",
    "\n",
    "    #roc_auc_score(y_true, y_pred)]\n",
    "\n",
    "def AnswerWithDiversity(k1,tagList,posClassLen):\n",
    "\n",
    "    print(posClassLen)\n",
    "\n",
    "    NonMainSetArray = []\n",
    "    MainSetArray = []\n",
    "\n",
    "\n",
    "    kret = np.zeros(len(k1))\n",
    "    #print(len(tagList))\n",
    "    #print(len(k1))\n",
    "\n",
    "    k2 = []\n",
    "    for i in k1:\n",
    "        k2.append(i[1])\n",
    "    countSmall = 0\n",
    "    k2 = np.array(k2)\n",
    "    k3 = k2\n",
    "    adder = 10\n",
    "    print(adder)\n",
    "    #posClassLen = posClassLen+adder\n",
    "    posClassLen = 60\n",
    "\n",
    "    ind =  k3.argsort()[-posClassLen:][::-1]\n",
    "    #print ind\n",
    "    onlyRec = np.zeros(len(k2))\n",
    "    for i in ind:\n",
    "        onlyRec[i] = 1\n",
    "    for k2iter in range(len(k2)):\n",
    "        if k2iter not in ind:\n",
    "            word = tagList[k2iter].split('&')\n",
    "            thistoadd = {\"word\":word, \"score\":k2[k2iter], \"index\":k2iter}\t\n",
    "            NonMainSetArray.append(thistoadd)\n",
    "\n",
    "    LossWordSet = []\n",
    "\n",
    "    lossCal = 0\n",
    "    #print NonMainSetArray\n",
    "\n",
    "    for indIter in ind:\n",
    "        word = tagList[indIter].split('&')\n",
    "        score = 0\n",
    "        numberAddedat = []\n",
    "        for wordIter in word:\n",
    "            flag = 0\n",
    "            for LossWordSetIter in LossWordSet:\n",
    "                if wordIter == LossWordSetIter[\"word\"]:\n",
    "                    flag = 1\n",
    "\n",
    "                    LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"]+1\n",
    "                    score = score+(k2[indIter]/LossWordSetIter[\"number\"])\n",
    "                    numberAddedat.append(LossWordSetIter)\n",
    "\n",
    "                    break\n",
    "\n",
    "            if flag == 0:\n",
    "                thistoadd = {\"word\":wordIter, \"number\":1}\n",
    "                LossWordSet.append(thistoadd)\n",
    "                numberAddedat.append(thistoadd)\n",
    "                score = score+k2[indIter]\n",
    "\n",
    "\n",
    "        #print (\"LossWordSet\")\n",
    "        #print LossWordSet\n",
    "        #for i in MainSetArray:\n",
    "            #print (\"MainSetArray\")\n",
    "        #\tprint i\n",
    "        #\tbreak\n",
    "\n",
    "        lossCal = lossCal + score\n",
    "        #print (\"numberAddedat\")\n",
    "        #print numberAddedat\n",
    "        TobeaddedinLoop = numberAddedat\n",
    "        thistoadd = {\"word\":TobeaddedinLoop, \"score\":k2[indIter], \"index\":indIter}\n",
    "        MainSetArray.append(thistoadd)\n",
    "\n",
    "    #print lossCal\n",
    "    #print(len(MainSetArray))\n",
    "    for kappa in range(500):\n",
    "        flagMain = 0\n",
    "        #print kappa\n",
    "        for i in reversed(MainSetArray):\n",
    "\n",
    "            score = 0\n",
    "            for wordIter in i[\"word\"]:\n",
    "                for LossWordSetIter in LossWordSet:\n",
    "                    if wordIter[\"word\"] == LossWordSetIter[\"word\"]:\n",
    "                        score = score+ (i[\"score\"]/LossWordSetIter[\"number\"])\n",
    "                        LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] - 1\n",
    "\n",
    "            for j in NonMainSetArray:\n",
    "                numberAddedat = []\n",
    "                score2 = 0\n",
    "                for wordIter in j[\"word\"]:\n",
    "                    for LossWordSetIter in LossWordSet:\n",
    "\n",
    "                        if wordIter == LossWordSetIter[\"word\"]:\n",
    "                            LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] + 1\n",
    "                            score2 = score2+ (j[\"score\"]/LossWordSetIter[\"number\"])\n",
    "                            numberAddedat.append(LossWordSetIter)\n",
    "\n",
    "                if score2 - score > 0:\n",
    "                    wordset = []\n",
    "                    for wordIter in i[\"word\"]:\n",
    "                        wordset.append(wordIter[\"word\"])\n",
    "                    thistoadd = {\"word\":wordset, \"score\":i[\"score\"], \"index\":i[\"index\"]}\t\n",
    "                    NonMainSetArray.append(thistoadd)\n",
    "\n",
    "                    thistoadd = {\"word\":numberAddedat, \"score\":j[\"score\"], \"index\":j[\"index\"]}\t\n",
    "\n",
    "                    MainSetArray.append(thistoadd)\n",
    "                    NonMainSetArray.remove(j)\n",
    "                    MainSetArray.remove(i)\n",
    "                    flagMain = 1\n",
    "                    break\n",
    "\n",
    "                for wordIter in j[\"word\"]:\n",
    "                    for LossWordSetIter in LossWordSet:\n",
    "                        if wordIter == LossWordSetIter[\"word\"]:\n",
    "                            LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] - 1\n",
    "\n",
    "\n",
    "            if flagMain == 1:\n",
    "                break\n",
    "\n",
    "            for wordIter in i[\"word\"]:\n",
    "                for LossWordSetIter in LossWordSet:\n",
    "                    if wordIter[\"word\"] == LossWordSetIter[\"word\"]:\n",
    "                        LossWordSetIter[\"number\"] = LossWordSetIter[\"number\"] + 1\n",
    "\n",
    "\n",
    "\n",
    "        if flagMain == 0:\n",
    "            break\n",
    "    for i in MainSetArray:\n",
    "        kret[i[\"index\"]] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #print MainSetArray\n",
    "    #print LossWordSet\n",
    "\n",
    "    return kret,onlyRec\n",
    "\n",
    "\n",
    "\n",
    "revmle = []\n",
    "recmle = []\n",
    "ymle = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94798\n",
      "94798\n",
      "count\n",
      "94798\n",
      "1\n",
      "141\n",
      "(141, 2)\n",
      "(141,)\n",
      "(141,)\n",
      "(141,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "34\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.71631205673758869, array([ 0.78723404,  0.57446809]), array([ 0.91358025,  0.45      ]), array([ 0.69158879,  0.79411765])]\n",
      "WithonlyRec\n",
      "SVM\t[0.68794326241134751, array([ 0.76595745,  0.53191489]), array([ 0.88888889,  0.41666667]), array([ 0.6728972 ,  0.73529412])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.78723404255319152, array([ 0.85714286,  0.58333333]), array([ 0.87378641,  0.55263158]), array([ 0.8411215 ,  0.61764706])]\n",
      "258\n",
      "(117, 2)\n",
      "(117,)\n",
      "(117,)\n",
      "(117,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "11\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.5641025641025641, array([ 0.68711656,  0.28169014]), array([ 0.98245614,  0.16666667]), array([ 0.52830189,  0.90909091])]\n",
      "WithonlyRec\n",
      "SVM\t[0.5641025641025641, array([ 0.68711656,  0.28169014]), array([ 0.98245614,  0.16666667]), array([ 0.52830189,  0.90909091])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.81196581196581197, array([ 0.88659794,  0.45      ]), array([ 0.97727273,  0.31034483]), array([ 0.81132075,  0.81818182])]\n",
      "427\n",
      "(169, 2)\n",
      "(169,)\n",
      "(169,)\n",
      "(169,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "33\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.74556213017751483, array([ 0.8244898 ,  0.53763441]), array([ 0.9266055 ,  0.41666667]), array([ 0.74264706,  0.75757576])]\n",
      "WithonlyRec\n",
      "SVM\t[0.75739644970414199, array([ 0.83265306,  0.55913978]), array([ 0.93577982,  0.43333333]), array([ 0.75      ,  0.78787879])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.84023668639053251, array([ 0.89655172,  0.64935065]), array([ 0.936     ,  0.56818182]), array([ 0.86029412,  0.75757576])]\n",
      "674\n",
      "(247, 2)\n",
      "(247,)\n",
      "(247,)\n",
      "(247,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "48\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.80566801619433204, array([ 0.87564767,  0.55555556]), array([ 0.90374332,  0.5       ]), array([ 0.84924623,  0.625     ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.81376518218623484, array([ 0.88082902,  0.57407407]), array([ 0.90909091,  0.51666667]), array([ 0.85427136,  0.64583333])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.78947368421052633, array([ 0.85714286,  0.6       ]), array([ 0.94545455,  0.47560976]), array([ 0.7839196,  0.8125   ])]\n",
      "852\n",
      "(178, 2)\n",
      "(178,)\n",
      "(178,)\n",
      "(178,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "32\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.7415730337078652, array([ 0.82575758,  0.5       ]), array([ 0.92372881,  0.38333333]), array([ 0.74657534,  0.71875   ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.7528089887640449, array([ 0.83333333,  0.52173913]), array([ 0.93220339,  0.4       ]), array([ 0.75342466,  0.75      ])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.7696629213483146, array([ 0.84644195,  0.53932584]), array([ 0.9338843 ,  0.42105263]), array([ 0.7739726,  0.75     ])]\n",
      "1001\n",
      "1128\n",
      "(276, 2)\n",
      "(276,)\n",
      "(276,)\n",
      "(276,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "38\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.80434782608695654, array([ 0.88105727,  0.44897959]), array([ 0.92592593,  0.36666667]), array([ 0.84033613,  0.57894737])]\n",
      "WithonlyRec\n",
      "SVM\t[0.81159420289855078, array([ 0.88546256,  0.46938776]), array([ 0.93055556,  0.38333333]), array([ 0.84453782,  0.60526316])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.76086956521739135, array([ 0.84792627,  0.44067797]), array([ 0.93877551,  0.325     ]), array([ 0.77310924,  0.68421053])]\n",
      "1442\n",
      "(314, 2)\n",
      "(314,)\n",
      "(314,)\n",
      "(314,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "47\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.8439490445859873, array([ 0.9059501 ,  0.54205607]), array([ 0.92913386,  0.48333333]), array([ 0.88389513,  0.61702128])]\n",
      "WithonlyRec\n",
      "SVM\t[0.85031847133757965, array([ 0.90978887,  0.56074766]), array([ 0.93307087,  0.5       ]), array([ 0.88764045,  0.63829787])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.81847133757961787, array([ 0.88484848,  0.57142857]), array([ 0.96052632,  0.44186047]), array([ 0.82022472,  0.80851064])]\n",
      "1733\n",
      "(291, 2)\n",
      "(291,)\n",
      "(291,)\n",
      "(291,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "46\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.82130584192439859, array([ 0.8907563 ,  0.50943396]), array([ 0.91774892,  0.45      ]), array([ 0.86530612,  0.58695652])]\n",
      "WithonlyRec\n",
      "SVM\t[0.81443298969072164, array([ 0.88655462,  0.49056604]), array([ 0.91341991,  0.43333333]), array([ 0.86122449,  0.56521739])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.80068728522336774, array([ 0.87280702,  0.53968254]), array([ 0.94312796,  0.425     ]), array([ 0.8122449 ,  0.73913043])]\n",
      "1881\n",
      "(148, 2)\n",
      "(148,)\n",
      "(148,)\n",
      "(148,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "16\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.67567567567567566, array([ 0.78181818,  0.36842105]), array([ 0.97727273,  0.23333333]), array([ 0.65151515,  0.875     ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.66216216216216217, array([ 0.77272727,  0.34210526]), array([ 0.96590909,  0.21666667]), array([ 0.64393939,  0.8125    ])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.81081081081081086, array([ 0.88617886,  0.44      ]), array([ 0.95614035,  0.32352941]), array([ 0.82575758,  0.6875    ])]\n",
      "2001\n",
      "2086\n",
      "(205, 2)\n",
      "(205,)\n",
      "(205,)\n",
      "(205,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "31\n",
      "10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WithDiversity\n",
      "SVM\t[0.80975609756097566, array([ 0.87774295,  0.57142857]), array([ 0.96551724,  0.43333333]), array([ 0.8045977 ,  0.83870968])]\n",
      "WithonlyRec\n",
      "SVM\t[0.80000000000000004, array([ 0.87147335,  0.54945055]), array([ 0.95862069,  0.41666667]), array([ 0.79885057,  0.80645161])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.83902439024390241, array([ 0.90030211,  0.58227848]), array([ 0.94904459,  0.47916667]), array([ 0.85632184,  0.74193548])]\n",
      "2384\n",
      "(298, 2)\n",
      "(298,)\n",
      "(298,)\n",
      "(298,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "48\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.79194630872483218, array([ 0.87295082,  0.42592593]), array([ 0.89495798,  0.38333333]), array([ 0.852     ,  0.47916667])]\n",
      "WithonlyRec\n",
      "SVM\t[0.78523489932885904, array([ 0.86885246,  0.40740741]), array([ 0.8907563 ,  0.36666667]), array([ 0.848     ,  0.45833333])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.78859060402684567, array([ 0.86509636,  0.51162791]), array([ 0.93087558,  0.40740741]), array([ 0.808 ,  0.6875])]\n",
      "2691\n",
      "(307, 2)\n",
      "(307,)\n",
      "(307,)\n",
      "(307,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "61\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.80781758957654726, array([ 0.88032454,  0.51239669]), array([ 0.87854251,  0.51666667]), array([ 0.88211382,  0.50819672])]\n",
      "WithonlyRec\n",
      "SVM\t[0.7947882736156352, array([ 0.87221095,  0.47933884]), array([ 0.87044534,  0.48333333]), array([ 0.87398374,  0.47540984])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.76221498371335505, array([ 0.83668904,  0.56287425]), array([ 0.93034826,  0.44339623]), array([ 0.7601626,  0.7704918])]\n",
      "3001\n",
      "3016\n",
      "(325, 2)\n",
      "(325,)\n",
      "(325,)\n",
      "(325,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "46\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.81538461538461537, array([ 0.88970588,  0.43396226]), array([ 0.91320755,  0.38333333]), array([ 0.86738351,  0.5       ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.82769230769230773, array([ 0.89705882,  0.47169811]), array([ 0.92075472,  0.41666667]), array([ 0.87455197,  0.54347826])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.78769230769230769, array([ 0.86227545,  0.53691275]), array([ 0.97297297,  0.38834951]), array([ 0.77419355,  0.86956522])]\n",
      "3319\n",
      "(303, 2)\n",
      "(303,)\n",
      "(303,)\n",
      "(303,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "47\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.83168316831683164, array([ 0.89779559,  0.52336449]), array([ 0.9218107 ,  0.46666667]), array([ 0.875     ,  0.59574468])]\n",
      "WithonlyRec\n",
      "SVM\t[0.80528052805280526, array([ 0.88176353,  0.44859813]), array([ 0.90534979,  0.4       ]), array([ 0.859375 ,  0.5106383])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.78217821782178221, array([ 0.86075949,  0.5       ]), array([ 0.93577982,  0.38823529]), array([ 0.796875  ,  0.70212766])]\n",
      "3646\n",
      "(327, 2)\n",
      "(327,)\n",
      "(327,)\n",
      "(327,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "46\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.81039755351681952, array([ 0.88686131,  0.41509434]), array([ 0.91011236,  0.36666667]), array([ 0.86476868,  0.47826087])]\n",
      "WithonlyRec\n",
      "SVM\t[0.77981651376146788, array([ 0.86861314,  0.32075472]), array([ 0.89138577,  0.28333333]), array([ 0.84697509,  0.36956522])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.7737003058103975, array([ 0.85658915,  0.46376812]), array([ 0.94042553,  0.34782609]), array([ 0.78647687,  0.69565217])]\n",
      "3809\n",
      "(163, 2)\n",
      "(163,)\n",
      "(163,)\n",
      "(163,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "16\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.71779141104294475, array([ 0.816     ,  0.39473684]), array([ 0.99029126,  0.25      ]), array([ 0.69387755,  0.9375    ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.71779141104294475, array([ 0.816     ,  0.39473684]), array([ 0.99029126,  0.25      ]), array([ 0.69387755,  0.9375    ])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.81595092024539873, array([ 0.88888889,  0.46428571]), array([ 0.97560976,  0.325     ]), array([ 0.81632653,  0.8125    ])]\n",
      "4001\n",
      "4039\n",
      "(230, 2)\n",
      "(230,)\n",
      "(230,)\n",
      "(230,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "31\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.83043478260869563, array([ 0.89430894,  0.57142857]), array([ 0.97058824,  0.43333333]), array([ 0.82914573,  0.83870968])]\n",
      "WithonlyRec\n",
      "SVM\t[0.83043478260869563, array([ 0.89430894,  0.57142857]), array([ 0.97058824,  0.43333333]), array([ 0.82914573,  0.83870968])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.85652173913043483, array([ 0.91338583,  0.58227848]), array([ 0.95604396,  0.47916667]), array([ 0.87437186,  0.74193548])]\n",
      "4308\n",
      "(269, 2)\n",
      "(269,)\n",
      "(269,)\n",
      "(269,)\n",
      "('Minimiser results: ',  final_simplex: (array([[ 0.7       ,  1.        ],\n",
      "       [ 0.70006836,  1.        ],\n",
      "       [ 0.7       ,  1.00009766]]), array([-0., -0., -0.]))\n",
      "           fun: -0.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 39\n",
      "           nit: 10\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.7,  1. ]), array([ 0.7,  1. ]))\n",
      "0.7\n",
      "46\n",
      "10\n",
      "WithDiversity\n",
      "SVM\t[0.77695167286245348, array([ 0.86111111,  0.43396226]), array([ 0.88995215,  0.38333333]), array([ 0.83408072,  0.5       ])]\n",
      "WithonlyRec\n",
      "SVM\t[0.77695167286245348, array([ 0.86111111,  0.43396226]), array([ 0.88995215,  0.38333333]), array([ 0.83408072,  0.5       ])]\n",
      "WithoutDiversity\n",
      "SVM\t[0.7806691449814126, array([ 0.85644769,  0.53543307]), array([ 0.93617021,  0.41975309]), array([ 0.78923767,  0.73913043])]\n",
      "4596\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bd5c5054987a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-bd5c5054987a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mtodayDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimetuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mTestmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_class_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative_class_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpositive_tagList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative_tagList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtodayDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mposart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_class_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-bd5c5054987a>\u001b[0m in \u001b[0;36mTestmain\u001b[0;34m(positive_class, negative_class, d1, positive_tagList, negative_tagList, todayDate)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abstract\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"authorList\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tagList\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"topics\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tonetype\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"relarticle300\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"relarticle1500\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtagList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtimestampList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def Testmain(positive_class,negative_class,d1,positive_tagList,negative_tagList,todayDate):\n",
    "    print(d1)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    a = []\n",
    "    tagList = []\n",
    "    #print (len(positive_tagList))\n",
    "    #print (len(negative_tagList))\n",
    "    #print (len(negative_class))\n",
    "    timestampList = []\n",
    "\n",
    "    timenow = todayDate\n",
    "\n",
    "    posClassLen = len(positive_class)\n",
    "    for i,i1 in zip(negative_class,negative_tagList):\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"]), int(i[\"numberOfWords\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        X_test.append(a)\n",
    "        y_test.append(0)\n",
    "        tagList.append(i1)\n",
    "        timestampList.append(float(i[\"timestamp\"]))\n",
    "\n",
    "    for i,i1 in zip(positive_class,positive_tagList):\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"]), int(i[\"numberOfWords\"])]\n",
    "        #a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])] \n",
    "        a = [int(i[\"abstract\"]),int(i[\"authorList\"]),int(i[\"tagList\"]),int(i[\"topics\"]),int(i[\"tonetype\"]), int(i[\"relarticle300\"]), int(i[\"relarticle1500\"])]\n",
    "        X_test.append(a)\n",
    "        y_test.append(1)\n",
    "        tagList.append(i1)\n",
    "        timestampList.append(float(i[\"timestamp\"]))\n",
    "\n",
    "    #print X_test[0]\n",
    "\n",
    "    X_test = numpy.array(X_test)\n",
    "    y_test = numpy.array(y_test)\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #X_test = min_max_scaler.fit_transform(X_test)\t\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    X_test = preprocessing.normalize(X_test, norm='l2')\n",
    "    #print X_test[0]\n",
    "    model = None\n",
    "\n",
    "    timestampList = numpy.array(timestampList)\n",
    "\n",
    "\n",
    "    for ia in range(len(timestampList)):\n",
    "        if timenow - timestampList[ia] != 0:\n",
    "            timestampList[ia] = 1/(timenow - timestampList[ia])\n",
    "        else:\n",
    "            print(\"timenow-timstamp = 0\")\n",
    "        if timestampList[ia] <= 0:\n",
    "            print(\"recency is zero\")\n",
    "\n",
    "    tmax = numpy.amax(timestampList)\n",
    "    for ia in range(len(timestampList)):\n",
    "        timestampList[ia] = timestampList[ia]/tmax\n",
    "\n",
    "    for name in names:\n",
    "        with open(model_path+\"/\"+name +\"Newcount\"+str(d1)+'.pkl', 'rb') as f1:\n",
    "            model = pickle.load(f1)\n",
    "\n",
    "        k1 = model.predict_proba(X_test)\n",
    "\n",
    "        print(k1.shape)\n",
    "        revmleBefore = []\n",
    "        for ia in range(len(k1)):\n",
    "            revmleBefore.append(k1[ia][1])\n",
    "\n",
    "        revmle = numpy.array(revmleBefore)\n",
    "        recmle = timestampList\n",
    "        ymle = y_test\n",
    "\n",
    "        print(revmle.shape)\n",
    "        print(recmle.shape)\n",
    "        print(ymle.shape)\n",
    "        # Make a list of initial parameter guesses (b0, b1, sd)    \n",
    "        initParams = [0.7, 1]\n",
    "\n",
    "        # Run the minimizer\n",
    "        results = minimize(regressLL, initParams, method='nelder-mead')\n",
    "        print(\"Minimiser results: \",results, results.x)\n",
    "        alpha = results['x'][0]\n",
    "        print(alpha)\n",
    "\n",
    "        for ia in range(len(k1)):\n",
    "            k1[ia][1] = alpha*k1[ia][1]+(1-alpha)*timestampList[ia]\n",
    "\n",
    "\n",
    "        k,knew = AnswerWithDiversity(k1,tagList,posClassLen)\n",
    "        scores = evaluate(y_test,k)\n",
    "        scores1 = evaluate(y_test,knew)\n",
    "        print(\"WithDiversity\")\n",
    "        print(name+\"\\t\"+str(scores))\n",
    "        print(\"WithonlyRec\")\n",
    "        print(name+\"\\t\"+str(scores1))\n",
    "        k = model.predict(X_test)\n",
    "        countSmall = 0\n",
    "        for ka in k:\n",
    "            if ka == 1:\n",
    "                countSmall = countSmall + 1\n",
    "        scores = evaluate(y_test,k)\n",
    "        #print countSmall\n",
    "        print(\"WithoutDiversity\")\n",
    "        print(name+\"\\t\"+str(scores))\n",
    "\n",
    "    #numpy.save('urlThis'+str(month)+'.npy',urlThis)\n",
    "    #print(len(urlThis))\n",
    "\n",
    "\n",
    "def main():\n",
    "    allFeatureVal = numpy.load('../FeatureInValueForm/FeatureInValueFormwithPublishDateOrdered.npy')\n",
    "    print(len(allFeatureVal))\n",
    "    relatedarticletonum = numpy.load('../FeatureInTextFormSorted/FeatureInTextFormSortedOrdered.npy')\t\n",
    "    print(len(relatedarticletonum))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(allFeatureVal)):\n",
    "        if allFeatureVal[i][\"url\"] == relatedarticletonum[i][\"url\"]:\n",
    "            count = count +1\n",
    "        #else :\n",
    "            #print(\"I m here prob\")\n",
    "    print(\"count\")\n",
    "    print(count)\t\n",
    "\n",
    "\n",
    "    #for i in range(len(relatedarticletonum))\n",
    "\n",
    "    positive_class_test = []\n",
    "    negative_class_test = []\n",
    "    count = 0\n",
    "    posart = 0\n",
    "    negart = 0\n",
    "    positive_tagList = []\n",
    "    negative_tagList = []\n",
    "    prev = 0\n",
    "    for data,tagList in zip(allFeatureVal,relatedarticletonum):\n",
    "        a = data[\"dateList\"].decode('UTF-8')\n",
    "        d1 = datetime.strptime(a, \"%Y-%m-%d\")\n",
    "        if d1.year > 2015:\n",
    "\n",
    "            if d1 != prev and count!=0 :\n",
    "\n",
    "                todayDate = time.mktime(datetime.strptime(a, \"%Y-%m-%d\").timetuple())\n",
    "\n",
    "                Testmain(positive_class_test,negative_class_test,count,positive_tagList,negative_tagList,todayDate)\n",
    "\n",
    "                posart = posart + len(positive_class_test)\n",
    "                negart = negart  + len(negative_class_test)\n",
    "\n",
    "                positive_class_test = []\n",
    "                negative_class_test = []\n",
    "                positive_tagList = []\n",
    "                negative_tagList = []\t\t\t\n",
    "\n",
    "            if int(data[\"output\"]) == 1:\n",
    "                positive_class_test.append(data)\n",
    "                positive_tagList.append(tagList[\"tagList\"].decode('UTF-8'))\n",
    "            else:\n",
    "                negative_class_test.append(data)\n",
    "                negative_tagList.append(tagList[\"tagList\"].decode('UTF-8'))\n",
    "\n",
    "            if count%1000 == 1:\n",
    "                print(count)\n",
    "            count = count+1\t\n",
    "            prev = d1\n",
    "\n",
    "        if count > 40000:\n",
    "            break\n",
    "\n",
    "    posart = posart + len(positive_class_test)\n",
    "    negart = negart  + len(negative_class_test)\n",
    "    #Testmain(positive_class_test,negative_class_test,len(allFeatureVal))\n",
    "    print(posart)\n",
    "    print(negart)\n",
    "    print(posart+negart)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
